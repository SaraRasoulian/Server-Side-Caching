## Caching

Caching means storing frequently used data in a temporary storage called a cache. Its main purpose is to speed up data delivery to users by avoiding repeated fetching from the original source.

Caching reduces the time and resources needed to fetch data, making systems faster and improving user experience.

## Server-side Caching in .NET

There are different ways to implement server-side caching in a .NET project. 3 commonly used techniques include:

### 1. In-Memory Caching

In this technique, the application stores temporary data in the main memory (RAM). It's lightweight and suitable when caching is needed within a single instance of an application.

.NET Core provides `IMemoryCache` interface for managing in-memory caching. It's useful for caching small amounts of data.

### 2. Distributed Caching

Distributed caching involves using a shared cache across multiple instances of an application. This avoids the performance bottlenecks of having a large cache on a single server. Data consistency is maintained across servers, even if one server restarts.
Distributed caching is suitable for applications with a microservices architecture.

In .NET Core, popular options for distributed caching include:

- Redis Cache
- SQL Server Cache
- NCache
  
.NET Applications interact with distributed caches using `IDistributedCache` interface.

### 3. Response Caching

Response caching is specific to web applications. It involves caching entire HTTP responses generated by action methods.

.NET Core provides `[ResponseCache]` attribute and configuration options to enable response caching.

---
These caching techniques help optimize application performance, reduce latency, and enhance user experience by delivering data faster and more efficiently.
